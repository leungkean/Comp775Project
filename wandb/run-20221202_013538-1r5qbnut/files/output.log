
[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to /Users/keanl/tensorflow_datasets/retina/1.0.0...
2022-12-02 01:35:47.291380: W tensorflow/core/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with "NOT_FOUND: Could not locate the credentials file.". Retrieving token from GCE failed with "FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata".
Metal device set to: Apple M1
systemMemory: 8.00 GB
maxCacheSize: 2.67 GB
Downloading...
From: https://drive.google.com/uc?id=1JAhPj63jo9II6Ed2TBvFi4Iet4faZwnw
To: /Users/keanl/tensorflow_datasets/downloads/retina_data.pkl
100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.0M/13.0M [00:00<00:00, 29.2MB/s]
Generating splits...:   0%|                                                                                                                                                            | 0/3 [00:00<?, ? splits/s]


Generating validation examples...: 12 examples [00:00, 105.39 examples/s]
[1mDataset retina downloaded and prepared to /Users/keanl/tensorflow_datasets/retina/1.0.0. Subsequent calls will reuse this data.
Model: "u_net"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 x (InputLayer)                 [(None, 128, 128, 1  0           []
                                )]
 b (InputLayer)                 [(None, 128, 128, 1  0           []
                                )]
 multiply (Multiply)            (None, 128, 128, 1)  0           ['x[0][0]',
                                                                  'b[0][0]']
 conv2d (Conv2D)                (None, 128, 128, 64  640         ['multiply[0][0]']
                                )
 conv2d_1 (Conv2D)              (None, 128, 128, 64  36928       ['conv2d[0][0]']
                                )
 dropout (Dropout)              (None, 128, 128, 64  0           ['conv2d_1[0][0]']
                                )
 max_pooling2d (MaxPooling2D)   (None, 64, 64, 64)   0           ['dropout[0][0]']
 conv2d_2 (Conv2D)              (None, 64, 64, 128)  73856       ['max_pooling2d[0][0]']
 conv2d_3 (Conv2D)              (None, 64, 64, 128)  147584      ['conv2d_2[0][0]']
 up_sampling2d (UpSampling2D)   (None, 128, 128, 12  0           ['conv2d_3[0][0]']
                                8)
 conv2d_4 (Conv2D)              (None, 128, 128, 64  32832       ['up_sampling2d[0][0]']
                                )
 concatenate (Concatenate)      (None, 128, 128, 12  0           ['conv2d_1[0][0]',
                                8)                                'conv2d_4[0][0]']
 conv2d_5 (Conv2D)              (None, 128, 128, 64  73792       ['concatenate[0][0]']
                                )
 conv2d_6 (Conv2D)              (None, 128, 128, 64  36928       ['conv2d_5[0][0]']
                                )
 conv2d_7 (Conv2D)              (None, 128, 128, 2)  1154        ['conv2d_6[0][0]']
 conv2d_8 (Conv2D)              (None, 128, 128, 1)  3           ['conv2d_7[0][0]']
==================================================================================================
Total params: 403,717
Trainable params: 403,717
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/20
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
2022-12-02 01:36:00.428564: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz









10/10 [==============================] - 75s 8s/step - loss: 0.5818 - accuracy: 0.8665 - val_loss: 0.5046 - val_accuracy: 0.8690 - _timestamp: 1669963034.0000 - _runtime: 96.0000
Epoch 2/20









10/10 [==============================] - 64s 5s/step - loss: 0.4883 - accuracy: 0.8675 - val_loss: 0.4625 - val_accuracy: 0.8690 - _timestamp: 1669963098.0000 - _runtime: 160.0000
Epoch 3/20









10/10 [==============================] - ETA: 0s - loss: 0.3893 - accuracy: 0.8675
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/threading.py", line 980, in _bootstrap_inner
    self.run()
  File "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/threading.py", line 917, in run
    self._target(*self._args, **self._kwargs)
  File "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/wandb/sdk/wandb_run.py", line 152, in check_network_status
    status_response = self._interface.communicate_network_status()
  File "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/wandb/sdk/interface/interface.py", line 138, in communicate_network_status
    resp = self._communicate_network_status(status)
  File "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py", line 405, in _communicate_network_status
    resp = self._communicate(req, local=True)
  File "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py", line 226, in _communicate
    return self._communicate_async(rec, local=local).get(timeout=timeout)
  File "/opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/wandb/sdk/interface/interface_shared.py", line 231, in _communicate_async
    raise Exception("The wandb backend process has shutdown")
